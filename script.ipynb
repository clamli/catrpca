{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE392: Robust Recovery from Tensor (Color Image or Video) Data Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from numpy import linalg as LA\n",
    "from numpy.linalg import multi_dot\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from colorsys import hls_to_rgb\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [The Berkeley Segmentation Dataset](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/)\n",
    "2. [Youtube](https://www.youtube.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Robust PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Video Surveillance.\n",
    "- Face Recognition.\n",
    "- Latent Semantic Indexing.\n",
    "- Ranking and Collaborative Filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key idea**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote a matrix $M$ as $M = L_{0} + S_{0}$, where $L_{0}$ is the low-rank representation of $M$ and $S_{0}$ captures the arbitrary corruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under two weak assumptions, i.e, the rank of the low-rank component is not too large and the sparse component is reasonably sparse, the problem defined above can be converted to the optimization problem,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$minimization\\  \\left \\| L \\right \\|_{*} + \\lambda\\left \\| S \\right \\|_{1},\\ s.t.\\ L+S = M$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solutions for this optimization problem serve as the best approximation of $L_{0}$ and $S_{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- works perfectly to recover the original noise-free matrix with a prior-known $\\lambda = \\frac{1}{max(n_{1}, n_{2})}$.\n",
    "- recovers matrix with $rank(L_{0}) = O(\\frac{n}{(logn)^{2}})$ and $cardinality(S_{0}) = O(n^{2})$, compared with paper of Chandrasekaran et. al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application (video)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one dimensional TRPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 TRPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prox_tnn: The proximal operator of the tensor nuclear norm of a 3 way tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proximal value for nuclear norm can be denoted as ${\\operatorname*{Prox}}_{\\lambda \\left\\| \\cdot \\right\\|_{*}} \\left( A \\right) = \\arg \\min_{X} \\frac{1}{2} \\left\\| X - A \\right\\|_{F}^{2} + \\lambda \\left\\| X \\right\\|_{*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Apply SVD on $A$: $A \\rightarrow U \\operatorname*{diag} \\left( \\boldsymbol{\\sigma} \\left( A \\right) \\right) {V}^{T}$\n",
    "2. Extract the vector of Singular Values $\\boldsymbol{\\sigma} \\left( A \\right)$.\n",
    "3. Calculate the Proximal Operator of the extracted vector using Vector Norm $p$: $\\hat{\\boldsymbol{\\sigma}} \\left( A \\right) = {\\operatorname*{Prox}}_{\\lambda \\left\\| \\cdot \\right\\|_{p}} \\left( \\boldsymbol{\\sigma} \\left( A \\right) \\right) = \\arg \\min_{x} \\frac{1}{2} \\left\\| x - \\boldsymbol{\\sigma} \\left( A \\right) \\right\\|_{2}^{2} + \\lambda \\left\\| x \\right\\|_{p}$\n",
    "4. Return the Proximal of the Matrix Norm: $\\hat{A} = {\\operatorname*{Prox}}_{\\lambda \\left\\| \\cdot \\right\\|_{p}} \\left( A \\right) = U \\operatorname*{diag} \\left( \\hat{\\boldsymbol{\\sigma}} \\left( A \\right) \\right) {V}^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the paper proposed that tensor-SVD can be efficiently computed based on the matrix SVD in the Fourier domain, since that the block circulant matrix can be mapped to a block diagonal matrix in the Fourier domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_tnn(Y, rho):\n",
    "    n1, n2, n3 = Y.shape\n",
    "    X = np.zeros((n1, n2, n3), dtype=complex)\n",
    "    Y = np.fft.fft(Y)\n",
    "    tnn = 0\n",
    "    trank = 0\n",
    "    U, S, V = np.linalg.svd(Y[:, :, 0], full_matrices=False)\n",
    "    r = np.sum(S > rho)\n",
    "    if r >= 1:\n",
    "        S = S[:r] - rho\n",
    "        X[:, :, 0] = multi_dot([U[:, :r], np.diag(S), V[:r, :]])\n",
    "        tnn += np.sum(S)\n",
    "        trank = max(trank, r)\n",
    "    halfn3 = round(n3/2)\n",
    "    for i in range(1, halfn3):\n",
    "        U, S, V = np.linalg.svd(Y[:, :, i], full_matrices=False)\n",
    "        r = np.sum(S > rho)\n",
    "        if r >= 1:\n",
    "            S = S[:r] - rho\n",
    "            X[:, :, i] = multi_dot([U[:, :r], np.diag(S), V[:r, :]])\n",
    "            tnn += np.sum(S)*2\n",
    "            trank = max(trank, r)\n",
    "        X[:, :, n3 - i] = np.conjugate(X[:, :, i])\n",
    "    if n3 % 2 == 0:\n",
    "        i = halfn3\n",
    "        U, S, V = np.linalg.svd(Y[:, :, i], full_matrices=False)\n",
    "        r = np.sum(S > rho)\n",
    "        if r >= 1:\n",
    "            S = S[:r] - rho\n",
    "            X[:, :, i] = multi_dot([U[:, :r], np.diag(S), V[:r, :]])\n",
    "            tnn += np.sum(S)\n",
    "            trank = max(trank, r)\n",
    "    tnn /= 3\n",
    "    X = np.fft.ifft(X)\n",
    "    return X, tnn, trank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prox_l1: The proximal operator of the l1 norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- $x$\n",
    "- $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "- $u$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proximal value for l1 norm of $u$ can be denoted as $\\operatorname{Prox}_{\\lambda {\\left\\| \\cdot \\right\\|}_{1}} \\left( x \\right) = \\arg \\min_{u} \\left\\{ \\frac{1}{2} {\\left\\| u - x \\right\\|}_{F}^{2} + \\lambda {\\left\\| u \\right\\|}_{1} \\right\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative can be calculated and the result will vanishes for $u_{i} = \\left\\{\\begin{matrix}\n",
    "           x_{i} - \\lambda,\\ for\\ x_{i} > \\lambda\\\\ \n",
    "           x_{i} + \\lambda,\\ for\\ x_{i} < -\\lambda\\\\\n",
    "           0, \\ for\\ -\\lambda \\leq x_{i} \\leq \\lambda\n",
    "           \\end{matrix}\\right.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l1(b, plambda):\n",
    "    return np.maximum(0, b - plambda) + np.minimum(0, b + plambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm TRPCA solved by ADMM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Update $\\mathcal{L} _{k+1}$ by the proximal operator of the tensor nuclear norm.\n",
    "2. Update $\\varepsilon _{k+1}$ by the proximal operator of the l1 norm.\n",
    "3. Update $\\mathcal{Y} _{k+1}$ by $\\mathcal{L} _{k+1}$, $\\varepsilon _{k+1}$ and $\\mathcal{X}$.\n",
    "4. Calculate convergence, if not converge, go to 1.\n",
    "5. Final $\\mathcal{L}$ is the recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trpca(X, plambda, tol=1e-8, max_iter=500, rho = 1.1, mu = 1e-4, max_mu = 1e10):\n",
    "    L = np.zeros(X.shape)\n",
    "    S = L\n",
    "    Y = L\n",
    "    for i in range(max_iter):\n",
    "        Lk = L\n",
    "        Sk = S\n",
    "        L, tnnL, _ = prox_tnn(-S + X - Y/mu, 1/mu)\n",
    "        S = prox_l1(-L + X - Y/mu, plambda/mu)\n",
    "        dY = L + S - X\n",
    "        chgL = np.max(abs(Lk - L))\n",
    "        chgS = np.max(abs(Sk - S))\n",
    "        chg = max(chgL, chgS, np.max(abs(dY)))\n",
    "        if chg < tol:\n",
    "            break\n",
    "        Y = Y + mu*dY\n",
    "        mu = min(rho*mu, max_mu)\n",
    "        \n",
    "        obj = tnnL + plambda * LA.norm(S.flatten(), ord=1)\n",
    "        err = LA.norm(dY.flatten(), ord=2)\n",
    "        print(\"Iter: %d/%d     Err: %.4f\"%(i+1, max_iter, err))\n",
    "    return L, S, obj, err, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"./Dataset/BSDS300-images/train/12074.jpg\")\n",
    "X = np.array(im).astype(\"float64\")\n",
    "X = X/255\n",
    "maxP = np.max(abs(X))\n",
    "n1, n2, n3 = X.shape\n",
    "Xn = np.copy(X)\n",
    "rhos = 0.3\n",
    "ind = np.random.rand(n1, n2, n3) < rhos\n",
    "ind[0:100, :, :] = False\n",
    "ind[200:, :, :] = False    # 100:150, 200:250\n",
    "ind[:, 0:200, :] = False\n",
    "ind[:, 300:, :] = False \n",
    "Xn[ind] = np.random.rand(np.sum(ind))\n",
    "mu = 1e-4\n",
    "max_mu = 1e10\n",
    "tol = 1e-5\n",
    "rho = 1.1\n",
    "max_iter = 500\n",
    "\n",
    "n1, n2, n3 = Xn.shape\n",
    "plambda = 1/np.sqrt(max(n1,n2)*n3)\n",
    "\n",
    "L, S, E, err, i = trpca(Xn, plambda, tol, max_iter, rho, mu, max_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X / np.max(X))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xn / np.max(Xn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xhat = L\n",
    "Xhat = np.maximum(Xhat, 0)\n",
    "Xhat = np.minimum(Xhat, maxP)\n",
    "plt.imshow(Xhat.real / np.max(Xhat.real))\n",
    "plt.axis('off')\n",
    "plt.savefig('rec6_rpca.png', format='png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psnr(Xhat.real, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 OTPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- handle outliers that and delibarate corruptions that are common in practical tensor data\n",
    "- develop a fast randomized algorithm which requires small sample size but gives great acceleration with no performance drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR-TPCA itself is similar to TRPCA, the only different is that for $\\varepsilon$, it solve $\\iota_{2,1}$ norm instead of $\\iota_{1}$ norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$\\operatorname{Prox}_{\\lambda {\\left\\| \\cdot \\right\\|}_{1}} \\left( x \\right) = \\arg \\min_{u} \\left\\{ \\frac{1}{2} {\\left\\| u - x \\right\\|}_{F}^{2} + \\lambda {\\left\\| u \\right\\|}_{1} \\right\\}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedures:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ramdomly sample a sub-tensor $X \\in \\mathbb{R}^{n_{1} \\times k \\times n_{3}}$ from $X$, where $k$ is much smaller than $n_{2}$. Hence, $X = [X_{l}, X_{r}]$, $L_{0} = [L_{l}, L_{r}]$,  $\\varepsilon_{0} = [\\varepsilon_{l}, \\varepsilon_{r}]$. OR-TPCA is first performed on the subset $X_{l}$.\n",
    "2. Apply $L_{l}$, $E_{l}$ to approximate the value of $L_{r}$ and $E_{r}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Corruption-Aware TPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "focus on the recovery of partial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rold(X, m, d=5, a=2, b=5, T=0.8):\n",
    "    n1, n2, n3 = X.shape\n",
    "    C = np.zeros((n1, n2, n3), dtype=bool)\n",
    "    V = np.zeros((n1, n2, n3))\n",
    "    N = d / 2\n",
    "    for i in range(n1):\n",
    "        print(\"%d/%d\"%(i+1, n1), end='\\r')\n",
    "        for j in range(n2):\n",
    "            for t in range(n3):\n",
    "                lr = int(max(0, i - N))\n",
    "                rr = int(min(i + N, n1))\n",
    "                lc = int(max(0, j - N))\n",
    "                rc = int(min(j + N, n2))\n",
    "                dst_lst = []\n",
    "                for r in range(lr, rr):\n",
    "                    for c in range(lc, rc):\n",
    "                        if r == i and c == j:\n",
    "                            continue\n",
    "                        dst_lst.append(max(math.log(abs(X[r, c, t] - X[i, j, t]) + 1e-8, a), -b) / b + 1)\n",
    "                rold = np.sum(np.sort(dst_lst)[0:m])\n",
    "                if rold > T:\n",
    "                    C[i, j, t] = False      # noise\n",
    "                    V[i, j, t] = rold\n",
    "                else:\n",
    "                    C[i, j, t] = True       # noise-free\n",
    "    return C, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_aw_trpca(X, plambda, C, tol=1e-8, max_iter=500, rho = 1.1, mu = 1e-4, max_mu = 1e10):\n",
    "    L = np.zeros(X.shape)\n",
    "    S = L\n",
    "    Y = L\n",
    "    for i in range(max_iter):\n",
    "        Lk = L\n",
    "        Sk = S\n",
    "        L, tnnL, _ = prox_tnn(-S + X - Y/mu, 1/mu)\n",
    "        S = prox_l1(-L + X - Y/mu, plambda/mu)\n",
    "        S[C] = 0\n",
    "        dY = L + S - X\n",
    "        chgL = np.max(abs(Lk - L))\n",
    "        chgS = np.max(abs(Sk - S))\n",
    "        chg = max(chgL, chgS, np.max(abs(dY)))\n",
    "        if chg < tol:\n",
    "            break\n",
    "        Y = Y + mu*dY\n",
    "        mu = min(rho*mu, max_mu)\n",
    "        \n",
    "        obj = tnnL + plambda * LA.norm(S.flatten(), ord=1)\n",
    "        err = LA.norm(dY.flatten(), ord=2)\n",
    "        print(\"Iter: %d/%d     Err: %.4f\"%(i+1, max_iter, err))\n",
    "    return L, S, obj, err, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"./Dataset/BSDS300-images/train/67079.jpg\")\n",
    "X = np.array(im).astype(\"float64\")\n",
    "X = X/255\n",
    "maxP = np.max(abs(X))\n",
    "n1, n2, n3 = X.shape\n",
    "Xn = np.copy(X)\n",
    "rhos = 0.3\n",
    "ind = np.random.rand(n1, n2, n3) < rhos\n",
    "ind[0:100, :, :] = False\n",
    "ind[200:, :, :] = False    # 100:150, 200:250\n",
    "ind[:, 0:200, :] = False\n",
    "ind[:, 300:, :] = False \n",
    "Xn[ind] = np.random.rand(np.sum(ind))\n",
    "C, V = rold(Xn, 8, d=5, a=2, b=3, T=0.80)\n",
    "mu = 1e-4\n",
    "max_mu = 1e10\n",
    "tol = 1e-5\n",
    "rho = 1.1\n",
    "max_iter = 500\n",
    "n1, n2, n3 = Xn.shape\n",
    "plambda = 1/np.sqrt(max(n1,n2)*n3)\n",
    "L, S, E, err, i = cor_aw_trpca(Xn, plambda, C, tol, max_iter, rho, mu, max_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X / np.max(X))\n",
    "plt.axis('off')\n",
    "plt.savefig('ori6.png', format='png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xn / np.max(Xn))\n",
    "plt.axis('off')\n",
    "plt.savefig('cor6.png', format='png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xhat = L\n",
    "Xhat = np.maximum(Xhat, 0)\n",
    "Xhat = np.minimum(Xhat, maxP)\n",
    "plt.imshow(Xhat.real / np.max(Xhat.real))\n",
    "plt.axis('off')\n",
    "plt.savefig('rec6_catrpca.png', format='png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psnr(Xhat.real, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Evaluation by PSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the PSNR, the better the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robust Recovery from Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract frames from videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_capture(path):\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "    count = 0\n",
    "    success = 1\n",
    "    while True:\n",
    "        success, image = vidObj.read()\n",
    "        if not success:\n",
    "            break\n",
    "#         image = image.astype(\"float64\") / 255\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        cv2.imwrite(\"./Dataset/Videos/italy_short/frame%d.jpg\" %(count), image)\n",
    "        if count == 0:\n",
    "            X = np.array(image).astype(\"float64\")[:, :, np.newaxis]\n",
    "        else:\n",
    "            X = np.concatenate((X, np.array(image).astype(\"float64\")[:, :, np.newaxis]), axis=2)\n",
    "        count += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_capture_single(path):\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "    count = 0\n",
    "    success = 1\n",
    "    while True:\n",
    "        success, image = vidObj.read()\n",
    "        if not success:\n",
    "            break\n",
    "#         image = image.astype(\"float64\") / 255\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        cv2.imwrite(\"./Dataset/Videos/italy_short/frame%d.jpg\" %(count), image)\n",
    "        \n",
    "        if count == 0:\n",
    "            X = np.array(image).astype(\"float64\").reshape(image.shape[0]*image.shape[1], 1)\n",
    "        else:\n",
    "            X = np.hstack((X, np.array(image).astype(\"float64\").reshape(image.shape[0]*image.shape[1], 1)))\n",
    "        count += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert frames back to videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(output_cor, video_name=\"./video.mp4\", fps=30, size=None):\n",
    "    height, width = output_cor[:, :, 0].shape\n",
    "    video = cv2.VideoWriter(video_name, 0, fps, (width, height))\n",
    "    for idx in range(output_cor.shape[2]):\n",
    "        layer = np.uint8(output_cor[:, :, idx] * 255)\n",
    "        X = layer[:, :, np.newaxis]\n",
    "        X = np.concatenate((X, layer[:, :, np.newaxis]), axis=2)\n",
    "        X = np.concatenate((X, layer[:, :, np.newaxis]), axis=2)\n",
    "        video.write(X)\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frame_capture(\"./Dataset/Videos/3_short.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255\n",
    "maxP = np.max(abs(X))\n",
    "n1, n2, n3 = X.shape\n",
    "Xn = np.copy(X)\n",
    "rhos = 0.3\n",
    "ind = np.random.rand(n1, n2, n3) < rhos\n",
    "Xn[ind] = np.random.rand(np.sum(ind))\n",
    "mu = 1e-4\n",
    "max_mu = 1e10\n",
    "tol = 1e-5\n",
    "rho = 1.1\n",
    "max_iter = 500\n",
    "n1, n2, n3 = Xn.shape\n",
    "plambda = 1/np.sqrt(max(n1,n2)*n3)\n",
    "L, S, E, err, i = trpca(Xn, plambda, tol, max_iter, rho, mu, max_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = frame_capture(\"./Dataset/Videos/4.mp4\")\n",
    "X = frame_capture(\"./Dataset/Videos/4.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255\n",
    "maxP = np.max(abs(X))\n",
    "n1, n2, n3 = X.shape\n",
    "Xn = np.copy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = 0.3\n",
    "ind = np.random.rand(n1, n2, n3) < rhos\n",
    "Xn[ind] = np.random.rand(np.sum(ind))\n",
    "mu = 1e-4\n",
    "max_mu = 1e10\n",
    "tol = 1e-5\n",
    "rho = 1.1\n",
    "max_iter = 500\n",
    "n1, n2, n3 = Xn.shape\n",
    "plambda = 1/np.sqrt(max(n1,n2)*n3)\n",
    "\n",
    "L = np.zeros(X.shape, dtype=complex)\n",
    "for i in range(X.shape[2]):\n",
    "    tmp, S, E, err, j = trpca(Xn[:, :, i][:, :, np.newaxis], plambda, tol, max_iter, rho, mu, max_mu)\n",
    "    L[:, :, i] = tmp.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corruption-Aware TPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frame_capture(\"./Dataset/Videos/4.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255\n",
    "maxP = np.max(abs(X))\n",
    "n1, n2, n3 = X.shape\n",
    "Xn = np.copy(X)\n",
    "ind = np.zeros((n1, n2, n3), dtype=bool)\n",
    "ind[100:125, 200:225, :] = True\n",
    "Xn[ind] = np.random.rand(np.sum(ind))\n",
    "C, V = rold(Xn, 8, d=5, a=2, b=3, T=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1e-4\n",
    "max_mu = 1e10\n",
    "tol = 1e-5\n",
    "rho = 1.1\n",
    "max_iter = 500\n",
    "n1, n2, n3 = Xn.shape\n",
    "plambda = 1/np.sqrt(max(n1,n2)*n3)\n",
    "L, S, E, err, i = cor_aw_trpca(Xn, plambda, C, tol, max_iter, rho, mu, max_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Robust Principal Component Analysis?](https://statweb.stanford.edu/~candes/papers/RobustPCA.pdf)\n",
    "2. [Tensor Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lu_Tensor_Robust_Principal_CVPR_2016_paper.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
